{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h:\\\\Codes\\\\PythonWorkspace\\\\CSE5005-Project\\\\demo'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bitcoin\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Network_delay.delayDistribution import randomDelay, randomDelayList, user_delay_normal_09\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_addr():\n",
    "    # 生成一个随机的密钥\n",
    "    while True:\n",
    "        # 生成一个用十六进制表示的长 256 位的私钥（str类型）\n",
    "        private_key = bitcoin.random_key()\n",
    "        # 解码为十进制的整形密钥\n",
    "        decoded_private_key = bitcoin.decode_privkey(private_key, \"hex\")\n",
    "        if 0 < decoded_private_key < bitcoin.N:\n",
    "            break\n",
    "    # print(private_key) #密钥（十六进制,长 256 位）\n",
    "\n",
    "    # 计算地址\n",
    "    # 用 WIF 格式编码密钥\n",
    "    wif_encoded_private_key = bitcoin.encode_privkey(decoded_private_key, \"wif\")\n",
    "    # 用 01 标识的压缩密钥\n",
    "    compressed_private_key = private_key + \"01\"\n",
    "    # 生成 WIF的压缩格式\n",
    "    wif_compressed_private_key = bitcoin.encode_privkey(\n",
    "        bitcoin.decode_privkey(compressed_private_key, \"hex\"), \"wif\"\n",
    "    )\n",
    "    # 计算公钥坐标 K = k * G\n",
    "    public_key = bitcoin.fast_multiply(bitcoin.G, decoded_private_key)\n",
    "    # 计算公钥\n",
    "    hex_encoded_public_key = bitcoin.encode_pubkey(public_key, \"hex\")\n",
    "    # 计算压缩公钥\n",
    "    # if public_key[1] % 2 == 0:  # 两种方式均可\n",
    "    if public_key[1] & 1 == 0:\n",
    "        compressed_prefix = \"02\"\n",
    "    else:\n",
    "        compressed_prefix = \"03\"\n",
    "    # 转十六也可用 bitcoin.encode(xxx, 16)\n",
    "    hex_compressed_public_key = compressed_prefix + hex(public_key[0])[2:]\n",
    "    # print(f'压缩公钥（十六进制）{hex_compressed_public_key} '\n",
    "    #      '（02 开头代表 y 是偶数，03 开头代表 y 是奇数）')\n",
    "    # 传入公钥坐标对象/十六进制公钥值，输出同样的地址\n",
    "    address = bitcoin.pubkey_to_address(public_key)\n",
    "    # print(address) #地址（b58check）（1 开头\n",
    "    return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>address</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1Ezzto898LdNa7aijuByjkRbgUbpa3NEFg</td>\n",
       "      <td>132.776393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1A1xJqpBTnE6kXWrkjmtSKDtxMY9sS19FP</td>\n",
       "      <td>86.586443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1NQGdTLwPfsgthJ4vjQq2Z6ba9igXxmWdP</td>\n",
       "      <td>108.590557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15QzFcs4LUJbEcDFt1GPgTzj6c8MsG7rHh</td>\n",
       "      <td>92.245653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17Sw92TxGD3Q4UZuCLCJpsG31nuTSgWNf2</td>\n",
       "      <td>163.863143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>1D9hw8xDkPRf5Fn4DtUG3e8RmJv7rJJLyc</td>\n",
       "      <td>10.158448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>17PvpdTm5NdStrAtfCn6jAhBc9udhcZtHe</td>\n",
       "      <td>70.044583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>1PBBCywffXkTT1gfztvpKFqo4G9X4xGXVX</td>\n",
       "      <td>89.850344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>1FFLCS655UG7h4F3p7w3tJR6jTvaqRiPYN</td>\n",
       "      <td>84.144983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>1FvoGPifwWUUEZJN2vEi2zy9QBr7t88bBm</td>\n",
       "      <td>217.508553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                             address        mean\n",
       "0          0  1Ezzto898LdNa7aijuByjkRbgUbpa3NEFg  132.776393\n",
       "1          1  1A1xJqpBTnE6kXWrkjmtSKDtxMY9sS19FP   86.586443\n",
       "2          2  1NQGdTLwPfsgthJ4vjQq2Z6ba9igXxmWdP  108.590557\n",
       "3          3  15QzFcs4LUJbEcDFt1GPgTzj6c8MsG7rHh   92.245653\n",
       "4          4  17Sw92TxGD3Q4UZuCLCJpsG31nuTSgWNf2  163.863143\n",
       "..       ...                                 ...         ...\n",
       "495      495  1D9hw8xDkPRf5Fn4DtUG3e8RmJv7rJJLyc   10.158448\n",
       "496      496  17PvpdTm5NdStrAtfCn6jAhBc9udhcZtHe   70.044583\n",
       "497      497  1PBBCywffXkTT1gfztvpKFqo4G9X4xGXVX   89.850344\n",
       "498      498  1FFLCS655UG7h4F3p7w3tJR6jTvaqRiPYN   84.144983\n",
       "499      499  1FvoGPifwWUUEZJN2vEi2zy9QBr7t88bBm  217.508553\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_user=500\n",
    "\n",
    "df_user = pd.DataFrame(columns=[\"user_id\", \"address\"])\n",
    "for i in range(num_user):\n",
    "    df_user.loc[i] = [i, gen_addr()]\n",
    "\n",
    "df_user[\"mean\"]=randomDelayList(num_user)\n",
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.to_csv(\"temp_user.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send_timestamp</th>\n",
       "      <th>recv_timestamp</th>\n",
       "      <th>latency</th>\n",
       "      <th>label</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-20 18:17:34.485413</td>\n",
       "      <td>2022-12-20 18:19:12.465123</td>\n",
       "      <td>97.979710</td>\n",
       "      <td>0</td>\n",
       "      <td>1MSa2dfnTgWRwdS7akjasH5cVbfCz29EZZ</td>\n",
       "      <td>13QehqQB3EavEToRxtnXcZ9t5aUm3aCdXE</td>\n",
       "      <td>1.021071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-20 18:17:34.487407</td>\n",
       "      <td>2022-12-20 18:20:03.059867</td>\n",
       "      <td>148.572460</td>\n",
       "      <td>0</td>\n",
       "      <td>15bkCmDRCwbbucAnbmxCM7zUpe27aUGV5a</td>\n",
       "      <td>1NXKmt9szwQEtU9WEgGzSyGeWRr84cnHHV</td>\n",
       "      <td>4.191815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-20 18:17:34.492394</td>\n",
       "      <td>2022-12-20 18:20:40.433076</td>\n",
       "      <td>185.940682</td>\n",
       "      <td>0</td>\n",
       "      <td>13KGnpWbLU7yJmu6mkfwvBRQffVPgwDYr9</td>\n",
       "      <td>1PEWb7j2WpE8mZmSxcbRsXM9wEqDg9CAjf</td>\n",
       "      <td>6.963535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20 18:17:34.496418</td>\n",
       "      <td>2022-12-20 18:20:12.930596</td>\n",
       "      <td>158.434178</td>\n",
       "      <td>0</td>\n",
       "      <td>1LTUZ9nneZ4ai2wxutaGF4ciJna3wCLwBe</td>\n",
       "      <td>1GCrxbzYr6a3wT9HGNvCcCYvW2sDT44vAe</td>\n",
       "      <td>6.148985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-20 18:17:34.499376</td>\n",
       "      <td>2022-12-20 18:19:29.704551</td>\n",
       "      <td>115.205175</td>\n",
       "      <td>0</td>\n",
       "      <td>1LkAkwf7pnNX9iW2FqJ7wDYvwkr2Hv1WBq</td>\n",
       "      <td>1Hk9uwt2rJjECvbdEwE4fhGCy2DNgBd86</td>\n",
       "      <td>3.296789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2022-12-20 18:17:45.944084</td>\n",
       "      <td>2022-12-20 18:17:58.858917</td>\n",
       "      <td>12.914833</td>\n",
       "      <td>0</td>\n",
       "      <td>1KoRhkUj12nrddw41iDXj1tQSMHZAVjAcH</td>\n",
       "      <td>14htnGJq3RiV4fV2t7dLWSdvKdtWt4Qu69</td>\n",
       "      <td>6.211750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2022-12-20 18:17:45.946078</td>\n",
       "      <td>2022-12-20 18:20:35.557217</td>\n",
       "      <td>169.611139</td>\n",
       "      <td>0</td>\n",
       "      <td>1EUAk62bEbyuSeLipb5yuXDon6wZ92KWmp</td>\n",
       "      <td>1LMHBLRpvwf8s6Nc5GKY2QDnmAwKApgaTV</td>\n",
       "      <td>0.694297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2022-12-20 18:17:45.948073</td>\n",
       "      <td>2022-12-20 18:19:00.775882</td>\n",
       "      <td>74.827809</td>\n",
       "      <td>0</td>\n",
       "      <td>1Gnyj18vDx8visBio6PtiPjk1sCPry2NhK</td>\n",
       "      <td>1NBpUy76e2SMKFKaXtAr65msFetjTPVLKn</td>\n",
       "      <td>0.112733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2022-12-20 18:17:45.951066</td>\n",
       "      <td>2022-12-20 18:20:25.877355</td>\n",
       "      <td>159.926289</td>\n",
       "      <td>0</td>\n",
       "      <td>164xoGoCX32FFFDWatKD7krVYD1FAc5Eic</td>\n",
       "      <td>1B6q1fziCwRaBAswLSnCv554LRfbBnjdJE</td>\n",
       "      <td>3.068479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2022-12-20 18:17:45.955054</td>\n",
       "      <td>2022-12-20 18:19:35.954638</td>\n",
       "      <td>109.999584</td>\n",
       "      <td>0</td>\n",
       "      <td>1DRbrtq3D47PzLwoHbLTtVC5xaAM7Anfec</td>\n",
       "      <td>1JwHPSesUuP5bZP1Cpi3GJJGnUkWCqaXxa</td>\n",
       "      <td>7.703944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 send_timestamp             recv_timestamp     latency  label  \\\n",
       "0    2022-12-20 18:17:34.485413 2022-12-20 18:19:12.465123   97.979710      0   \n",
       "1    2022-12-20 18:17:34.487407 2022-12-20 18:20:03.059867  148.572460      0   \n",
       "2    2022-12-20 18:17:34.492394 2022-12-20 18:20:40.433076  185.940682      0   \n",
       "3    2022-12-20 18:17:34.496418 2022-12-20 18:20:12.930596  158.434178      0   \n",
       "4    2022-12-20 18:17:34.499376 2022-12-20 18:19:29.704551  115.205175      0   \n",
       "...                         ...                        ...         ...    ...   \n",
       "4995 2022-12-20 18:17:45.944084 2022-12-20 18:17:58.858917   12.914833      0   \n",
       "4996 2022-12-20 18:17:45.946078 2022-12-20 18:20:35.557217  169.611139      0   \n",
       "4997 2022-12-20 18:17:45.948073 2022-12-20 18:19:00.775882   74.827809      0   \n",
       "4998 2022-12-20 18:17:45.951066 2022-12-20 18:20:25.877355  159.926289      0   \n",
       "4999 2022-12-20 18:17:45.955054 2022-12-20 18:19:35.954638  109.999584      0   \n",
       "\n",
       "                                    from                                  to  \\\n",
       "0     1MSa2dfnTgWRwdS7akjasH5cVbfCz29EZZ  13QehqQB3EavEToRxtnXcZ9t5aUm3aCdXE   \n",
       "1     15bkCmDRCwbbucAnbmxCM7zUpe27aUGV5a  1NXKmt9szwQEtU9WEgGzSyGeWRr84cnHHV   \n",
       "2     13KGnpWbLU7yJmu6mkfwvBRQffVPgwDYr9  1PEWb7j2WpE8mZmSxcbRsXM9wEqDg9CAjf   \n",
       "3     1LTUZ9nneZ4ai2wxutaGF4ciJna3wCLwBe  1GCrxbzYr6a3wT9HGNvCcCYvW2sDT44vAe   \n",
       "4     1LkAkwf7pnNX9iW2FqJ7wDYvwkr2Hv1WBq   1Hk9uwt2rJjECvbdEwE4fhGCy2DNgBd86   \n",
       "...                                  ...                                 ...   \n",
       "4995  1KoRhkUj12nrddw41iDXj1tQSMHZAVjAcH  14htnGJq3RiV4fV2t7dLWSdvKdtWt4Qu69   \n",
       "4996  1EUAk62bEbyuSeLipb5yuXDon6wZ92KWmp  1LMHBLRpvwf8s6Nc5GKY2QDnmAwKApgaTV   \n",
       "4997  1Gnyj18vDx8visBio6PtiPjk1sCPry2NhK  1NBpUy76e2SMKFKaXtAr65msFetjTPVLKn   \n",
       "4998  164xoGoCX32FFFDWatKD7krVYD1FAc5Eic  1B6q1fziCwRaBAswLSnCv554LRfbBnjdJE   \n",
       "4999  1DRbrtq3D47PzLwoHbLTtVC5xaAM7Anfec  1JwHPSesUuP5bZP1Cpi3GJJGnUkWCqaXxa   \n",
       "\n",
       "         value  \n",
       "0     1.021071  \n",
       "1     4.191815  \n",
       "2     6.963535  \n",
       "3     6.148985  \n",
       "4     3.296789  \n",
       "...        ...  \n",
       "4995  6.211750  \n",
       "4996  0.694297  \n",
       "4997  0.112733  \n",
       "4998  3.068479  \n",
       "4999  7.703944  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tx = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"send_timestamp\",\n",
    "            \"recv_timestamp\",\n",
    "            \"latency\",\n",
    "            \"label\",\n",
    "            \"from\",\n",
    "            \"to\",\n",
    "            \"value\",\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "n=5000\n",
    "for _ in range(n):\n",
    "    send_ts = datetime.datetime.now()\n",
    "    \n",
    "    from_user_idx=random.randint(0, len(df_user) - 1)\n",
    "    mean=df_user.loc[from_user_idx, \"mean\"]\n",
    "    \n",
    "    latency=user_delay_normal_09(mean, range=mean/10)\n",
    "    fluc = randomDelay()\n",
    "    latency = 0.7 * latency + 0.3 * fluc\n",
    "    \n",
    "    recv_ts = send_ts + datetime.timedelta(seconds=latency)\n",
    "    \n",
    "    from_user = df_user.loc[from_user_idx, \"address\"]\n",
    "    to_user = np.random.choice(df_user[\"address\"].values)\n",
    "    value = random.random() * 10\n",
    "    label = 0\n",
    "    \n",
    "    df_tx.loc[len(df_tx)]=[send_ts, recv_ts, latency, label, from_user, to_user, value]\n",
    "    \n",
    "df_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>send_timestamp</th>\n",
       "      <th>recv_timestamp</th>\n",
       "      <th>latency</th>\n",
       "      <th>label</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2022-12-20 18:17:35.418461</td>\n",
       "      <td>2022-12-20 18:17:42.289950</td>\n",
       "      <td>6.871489</td>\n",
       "      <td>0</td>\n",
       "      <td>1PGvY76CgJMSze1V48GZtRYA4K9kW4FnuD</td>\n",
       "      <td>1Q8kU6utjSvFX5ihxp672vubFs19R3TYaN</td>\n",
       "      <td>4.536026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2022-12-20 18:17:35.285525</td>\n",
       "      <td>2022-12-20 18:17:46.213868</td>\n",
       "      <td>10.928343</td>\n",
       "      <td>1</td>\n",
       "      <td>1PGvY76CgJMSze1V48GZtRYA4K9kW4FnuD</td>\n",
       "      <td>1PjLGcAEfR2otEpnSbZosigw6f3D7CHzN4</td>\n",
       "      <td>8.904795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>2022-12-20 18:17:39.633891</td>\n",
       "      <td>2022-12-20 18:17:49.359392</td>\n",
       "      <td>9.725501</td>\n",
       "      <td>0</td>\n",
       "      <td>1DUY2zzNFnmJbdCgytVmG2C6BswFM6P6gg</td>\n",
       "      <td>19voNhWY8vjk2NoBUU4L8wcBjzFyCxodqm</td>\n",
       "      <td>1.933107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2022-12-20 18:17:40.131160</td>\n",
       "      <td>2022-12-20 18:17:49.887297</td>\n",
       "      <td>9.756137</td>\n",
       "      <td>0</td>\n",
       "      <td>1KoRhkUj12nrddw41iDXj1tQSMHZAVjAcH</td>\n",
       "      <td>19mFjo1UpYePKgkmvg8s3MbAQztqGYm8cu</td>\n",
       "      <td>9.643031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2022-12-20 18:17:39.974757</td>\n",
       "      <td>2022-12-20 18:17:49.906923</td>\n",
       "      <td>9.932166</td>\n",
       "      <td>1</td>\n",
       "      <td>1PGvY76CgJMSze1V48GZtRYA4K9kW4FnuD</td>\n",
       "      <td>1HToxmkkWrZxHWn4YCrReMVRn8Nmk31pF1</td>\n",
       "      <td>3.569513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>2022-12-20 18:17:45.065585</td>\n",
       "      <td>2022-12-20 18:23:12.932648</td>\n",
       "      <td>327.867063</td>\n",
       "      <td>0</td>\n",
       "      <td>1EuLBroJ3AgtLYpsA2AGaMoU8WmuCKZccs</td>\n",
       "      <td>1Gnyj18vDx8visBio6PtiPjk1sCPry2NhK</td>\n",
       "      <td>2.816094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>2022-12-20 18:17:36.686598</td>\n",
       "      <td>2022-12-20 18:23:14.280656</td>\n",
       "      <td>337.594058</td>\n",
       "      <td>1</td>\n",
       "      <td>18h1WQWqcq7xYfoVXRbUQmnSxydrj76ufB</td>\n",
       "      <td>1GQFBpj3UcAkVLPEMwVK1h8s3Fgok5thmw</td>\n",
       "      <td>7.857793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>2022-12-20 18:17:43.316541</td>\n",
       "      <td>2022-12-20 18:23:24.123623</td>\n",
       "      <td>340.807082</td>\n",
       "      <td>0</td>\n",
       "      <td>18h1WQWqcq7xYfoVXRbUQmnSxydrj76ufB</td>\n",
       "      <td>1KT5y3DukrKrL4pbarjiEe5R32UVH1eSuo</td>\n",
       "      <td>8.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>2022-12-20 18:17:43.497766</td>\n",
       "      <td>2022-12-20 18:23:24.286253</td>\n",
       "      <td>340.788487</td>\n",
       "      <td>0</td>\n",
       "      <td>18h1WQWqcq7xYfoVXRbUQmnSxydrj76ufB</td>\n",
       "      <td>1QACHqmZN9w6uE1YfJkXyJQPvi87AuKdmj</td>\n",
       "      <td>6.413028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>2022-12-20 18:17:40.578008</td>\n",
       "      <td>2022-12-20 18:23:50.694326</td>\n",
       "      <td>370.116318</td>\n",
       "      <td>1</td>\n",
       "      <td>18h1WQWqcq7xYfoVXRbUQmnSxydrj76ufB</td>\n",
       "      <td>1FGUs922DdkkKypHP8mFN5DLf6Hvzy8Qo8</td>\n",
       "      <td>2.306968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 send_timestamp             recv_timestamp     latency  label  \\\n",
       "433  2022-12-20 18:17:35.418461 2022-12-20 18:17:42.289950    6.871489      0   \n",
       "368  2022-12-20 18:17:35.285525 2022-12-20 18:17:46.213868   10.928343      1   \n",
       "2305 2022-12-20 18:17:39.633891 2022-12-20 18:17:49.359392    9.725501      0   \n",
       "2512 2022-12-20 18:17:40.131160 2022-12-20 18:17:49.887297    9.756137      0   \n",
       "2447 2022-12-20 18:17:39.974757 2022-12-20 18:17:49.906923    9.932166      1   \n",
       "...                         ...                        ...         ...    ...   \n",
       "4680 2022-12-20 18:17:45.065585 2022-12-20 18:23:12.932648  327.867063      0   \n",
       "1039 2022-12-20 18:17:36.686598 2022-12-20 18:23:14.280656  337.594058      1   \n",
       "3898 2022-12-20 18:17:43.316541 2022-12-20 18:23:24.123623  340.807082      0   \n",
       "3977 2022-12-20 18:17:43.497766 2022-12-20 18:23:24.286253  340.788487      0   \n",
       "2722 2022-12-20 18:17:40.578008 2022-12-20 18:23:50.694326  370.116318      1   \n",
       "\n",
       "                                    from                                  to  \\\n",
       "433   1PGvY76CgJMSze1V48GZtRYA4K9kW4FnuD  1Q8kU6utjSvFX5ihxp672vubFs19R3TYaN   \n",
       "368   1PGvY76CgJMSze1V48GZtRYA4K9kW4FnuD  1PjLGcAEfR2otEpnSbZosigw6f3D7CHzN4   \n",
       "2305  1DUY2zzNFnmJbdCgytVmG2C6BswFM6P6gg  19voNhWY8vjk2NoBUU4L8wcBjzFyCxodqm   \n",
       "2512  1KoRhkUj12nrddw41iDXj1tQSMHZAVjAcH  19mFjo1UpYePKgkmvg8s3MbAQztqGYm8cu   \n",
       "2447  1PGvY76CgJMSze1V48GZtRYA4K9kW4FnuD  1HToxmkkWrZxHWn4YCrReMVRn8Nmk31pF1   \n",
       "...                                  ...                                 ...   \n",
       "4680  1EuLBroJ3AgtLYpsA2AGaMoU8WmuCKZccs  1Gnyj18vDx8visBio6PtiPjk1sCPry2NhK   \n",
       "1039  18h1WQWqcq7xYfoVXRbUQmnSxydrj76ufB  1GQFBpj3UcAkVLPEMwVK1h8s3Fgok5thmw   \n",
       "3898  18h1WQWqcq7xYfoVXRbUQmnSxydrj76ufB  1KT5y3DukrKrL4pbarjiEe5R32UVH1eSuo   \n",
       "3977  18h1WQWqcq7xYfoVXRbUQmnSxydrj76ufB  1QACHqmZN9w6uE1YfJkXyJQPvi87AuKdmj   \n",
       "2722  18h1WQWqcq7xYfoVXRbUQmnSxydrj76ufB  1FGUs922DdkkKypHP8mFN5DLf6Hvzy8Qo8   \n",
       "\n",
       "         value  \n",
       "433   4.536026  \n",
       "368   8.904795  \n",
       "2305  1.933107  \n",
       "2512  9.643031  \n",
       "2447  3.569513  \n",
       "...        ...  \n",
       "4680  2.816094  \n",
       "1039  7.857793  \n",
       "3898  8.677200  \n",
       "3977  6.413028  \n",
       "2722  2.306968  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tx.sort_values(by=\"recv_timestamp\", inplace=True)\n",
    "\n",
    "last_send_ts=datetime.datetime(1, 1, 1, 1, 1, 1)\n",
    "for index, row in df_tx.iterrows():\n",
    "    if row[\"send_timestamp\"]<last_send_ts:\n",
    "        df_tx.loc[index, \"label\"]=1\n",
    "    last_send_ts=row[\"send_timestamp\"]\n",
    "    \n",
    "df_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2505"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_tx[\"label\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list=df_user[\"address\"].values.tolist()\n",
    "\n",
    "def get_user_id(row):\n",
    "    from_user_id=user_list.index(row[\"from\"])\n",
    "    to_user_id=user_list.index(row[\"to\"])\n",
    "    \n",
    "    row[\"from_user_id\"]=from_user_id\n",
    "    row[\"to_user_id\"]=to_user_id\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recv_timestamp</th>\n",
       "      <th>latency</th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "      <th>from_user_id</th>\n",
       "      <th>to_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2022-12-20 18:17:42.289950</td>\n",
       "      <td>6.871489</td>\n",
       "      <td>0</td>\n",
       "      <td>4.536026</td>\n",
       "      <td>38</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2022-12-20 18:17:46.213868</td>\n",
       "      <td>10.928343</td>\n",
       "      <td>1</td>\n",
       "      <td>8.904795</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>2022-12-20 18:17:49.359392</td>\n",
       "      <td>9.725501</td>\n",
       "      <td>0</td>\n",
       "      <td>1.933107</td>\n",
       "      <td>368</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2022-12-20 18:17:49.887297</td>\n",
       "      <td>9.756137</td>\n",
       "      <td>0</td>\n",
       "      <td>9.643031</td>\n",
       "      <td>14</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2022-12-20 18:17:49.906923</td>\n",
       "      <td>9.932166</td>\n",
       "      <td>1</td>\n",
       "      <td>3.569513</td>\n",
       "      <td>38</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>2022-12-20 18:23:12.932648</td>\n",
       "      <td>327.867063</td>\n",
       "      <td>0</td>\n",
       "      <td>2.816094</td>\n",
       "      <td>47</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>2022-12-20 18:23:14.280656</td>\n",
       "      <td>337.594058</td>\n",
       "      <td>1</td>\n",
       "      <td>7.857793</td>\n",
       "      <td>280</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>2022-12-20 18:23:24.123623</td>\n",
       "      <td>340.807082</td>\n",
       "      <td>0</td>\n",
       "      <td>8.677200</td>\n",
       "      <td>280</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>2022-12-20 18:23:24.286253</td>\n",
       "      <td>340.788487</td>\n",
       "      <td>0</td>\n",
       "      <td>6.413028</td>\n",
       "      <td>280</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>2022-12-20 18:23:50.694326</td>\n",
       "      <td>370.116318</td>\n",
       "      <td>1</td>\n",
       "      <td>2.306968</td>\n",
       "      <td>280</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 recv_timestamp     latency  label     value  from_user_id  \\\n",
       "433  2022-12-20 18:17:42.289950    6.871489      0  4.536026            38   \n",
       "368  2022-12-20 18:17:46.213868   10.928343      1  8.904795            38   \n",
       "2305 2022-12-20 18:17:49.359392    9.725501      0  1.933107           368   \n",
       "2512 2022-12-20 18:17:49.887297    9.756137      0  9.643031            14   \n",
       "2447 2022-12-20 18:17:49.906923    9.932166      1  3.569513            38   \n",
       "...                         ...         ...    ...       ...           ...   \n",
       "4680 2022-12-20 18:23:12.932648  327.867063      0  2.816094            47   \n",
       "1039 2022-12-20 18:23:14.280656  337.594058      1  7.857793           280   \n",
       "3898 2022-12-20 18:23:24.123623  340.807082      0  8.677200           280   \n",
       "3977 2022-12-20 18:23:24.286253  340.788487      0  6.413028           280   \n",
       "2722 2022-12-20 18:23:50.694326  370.116318      1  2.306968           280   \n",
       "\n",
       "      to_user_id  \n",
       "433          244  \n",
       "368           41  \n",
       "2305         246  \n",
       "2512         164  \n",
       "2447         225  \n",
       "...          ...  \n",
       "4680          96  \n",
       "1039         454  \n",
       "3898         336  \n",
       "3977         269  \n",
       "2722          58  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data=df_tx.copy()\n",
    "df_data=df_data.apply(get_user_id, axis=1)\n",
    "\n",
    "df_data.drop(columns=[\"send_timestamp\", \"from\", \"to\"], inplace=True)\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"temp_data.pkl\"\n",
    "\n",
    "df_data.to_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset:\tx-torch.Size([3498, 2, 3])\ty-torch.Size([3498])\n",
      "Valset:  \tx-torch.Size([501, 2, 3])  \ty-torch.Size([501])\n",
      "Testset:\tx-torch.Size([999, 2, 3])\ty-torch.Size([999])\n",
      "2022-12-20 18:17:52.389777 Epoch 1 \tTrain Loss = 0.70182 Train acc = 0.52050  Val Loss = 0.72016 Val acc = 0.48596 \n",
      "2022-12-20 18:17:52.618163 Epoch 2 \tTrain Loss = 0.70119 Train acc = 0.51989  Val Loss = 0.72030 Val acc = 0.48157 \n",
      "2022-12-20 18:17:52.794691 Epoch 3 \tTrain Loss = 0.70037 Train acc = 0.52116  Val Loss = 0.71880 Val acc = 0.48239 \n",
      "2022-12-20 18:17:52.992162 Epoch 4 \tTrain Loss = 0.69900 Train acc = 0.52407  Val Loss = 0.71816 Val acc = 0.48157 \n",
      "2022-12-20 18:17:53.147756 Epoch 5 \tTrain Loss = 0.69838 Train acc = 0.52574  Val Loss = 0.71678 Val acc = 0.48677 \n",
      "2022-12-20 18:17:53.350335 Epoch 6 \tTrain Loss = 0.69793 Train acc = 0.52727  Val Loss = 0.71597 Val acc = 0.48791 \n",
      "2022-12-20 18:17:53.504920 Epoch 7 \tTrain Loss = 0.69692 Train acc = 0.52871  Val Loss = 0.71561 Val acc = 0.48629 \n",
      "2022-12-20 18:17:53.662499 Epoch 8 \tTrain Loss = 0.69657 Train acc = 0.52753  Val Loss = 0.71526 Val acc = 0.48629 \n",
      "2022-12-20 18:17:53.812387 Epoch 9 \tTrain Loss = 0.69530 Train acc = 0.53056  Val Loss = 0.71406 Val acc = 0.49060 \n",
      "2022-12-20 18:17:53.965977 Epoch 10 \tTrain Loss = 0.69477 Train acc = 0.53038  Val Loss = 0.71335 Val acc = 0.49060 \n",
      "2022-12-20 18:17:54.117570 Epoch 11 \tTrain Loss = 0.69384 Train acc = 0.53167  Val Loss = 0.71252 Val acc = 0.48548 \n",
      "2022-12-20 18:17:54.272158 Epoch 12 \tTrain Loss = 0.69326 Train acc = 0.53194  Val Loss = 0.71216 Val acc = 0.48662 \n",
      "2022-12-20 18:17:54.423752 Epoch 13 \tTrain Loss = 0.69274 Train acc = 0.53291  Val Loss = 0.71025 Val acc = 0.49491 \n",
      "2022-12-20 18:17:54.581039 Epoch 14 \tTrain Loss = 0.69159 Train acc = 0.53613  Val Loss = 0.71021 Val acc = 0.50118 \n",
      "2022-12-20 18:17:54.730901 Epoch 15 \tTrain Loss = 0.69121 Train acc = 0.53620  Val Loss = 0.70903 Val acc = 0.50240 \n",
      "2022-12-20 18:17:54.899553 Epoch 16 \tTrain Loss = 0.69031 Train acc = 0.53808  Val Loss = 0.70845 Val acc = 0.50158 \n",
      "2022-12-20 18:17:55.056949 Epoch 17 \tTrain Loss = 0.68991 Train acc = 0.53973  Val Loss = 0.70684 Val acc = 0.50988 \n",
      "2022-12-20 18:17:55.223023 Epoch 18 \tTrain Loss = 0.68887 Train acc = 0.54475  Val Loss = 0.70773 Val acc = 0.50818 \n",
      "2022-12-20 18:17:55.381554 Epoch 19 \tTrain Loss = 0.68798 Train acc = 0.54650  Val Loss = 0.70640 Val acc = 0.50427 \n",
      "2022-12-20 18:17:55.550103 Epoch 20 \tTrain Loss = 0.68745 Train acc = 0.54520  Val Loss = 0.70534 Val acc = 0.50158 \n",
      "2022-12-20 18:17:55.710674 Epoch 21 \tTrain Loss = 0.68681 Train acc = 0.54675  Val Loss = 0.70554 Val acc = 0.50151 \n",
      "2022-12-20 18:17:55.903159 Epoch 22 \tTrain Loss = 0.68634 Train acc = 0.54788  Val Loss = 0.70399 Val acc = 0.50940 \n",
      "2022-12-20 18:17:56.057256 Epoch 23 \tTrain Loss = 0.68560 Train acc = 0.54988  Val Loss = 0.70388 Val acc = 0.50656 \n",
      "2022-12-20 18:17:56.223810 Epoch 24 \tTrain Loss = 0.68499 Train acc = 0.55175  Val Loss = 0.70367 Val acc = 0.50851 \n",
      "2022-12-20 18:17:56.416941 Epoch 25 \tTrain Loss = 0.68431 Train acc = 0.55358  Val Loss = 0.70196 Val acc = 0.51599 \n",
      "2022-12-20 18:17:56.583277 Epoch 26 \tTrain Loss = 0.68355 Train acc = 0.55674  Val Loss = 0.70180 Val acc = 0.51957 \n",
      "2022-12-20 18:17:56.750829 Epoch 27 \tTrain Loss = 0.68303 Train acc = 0.55770  Val Loss = 0.70079 Val acc = 0.51835 \n",
      "2022-12-20 18:17:56.918801 Epoch 28 \tTrain Loss = 0.68253 Train acc = 0.55782  Val Loss = 0.70105 Val acc = 0.51795 \n",
      "2022-12-20 18:17:57.084358 Epoch 29 \tTrain Loss = 0.68184 Train acc = 0.56111  Val Loss = 0.70059 Val acc = 0.51445 \n",
      "2022-12-20 18:17:57.254901 Epoch 30 \tTrain Loss = 0.68132 Train acc = 0.56055  Val Loss = 0.69850 Val acc = 0.51964 \n",
      "2022-12-20 18:17:57.424447 Epoch 31 \tTrain Loss = 0.68076 Train acc = 0.56108  Val Loss = 0.69848 Val acc = 0.51835 \n",
      "2022-12-20 18:17:57.596986 Epoch 32 \tTrain Loss = 0.68023 Train acc = 0.56293  Val Loss = 0.69841 Val acc = 0.51828 \n",
      "2022-12-20 18:17:57.773789 Epoch 33 \tTrain Loss = 0.67971 Train acc = 0.56379  Val Loss = 0.69784 Val acc = 0.52698 \n",
      "2022-12-20 18:17:57.921199 Epoch 34 \tTrain Loss = 0.67918 Train acc = 0.56592  Val Loss = 0.69700 Val acc = 0.52502 \n",
      "2022-12-20 18:17:58.108858 Epoch 35 \tTrain Loss = 0.67833 Train acc = 0.56725  Val Loss = 0.69573 Val acc = 0.52819 \n",
      "2022-12-20 18:17:58.286844 Epoch 36 \tTrain Loss = 0.67790 Train acc = 0.57036  Val Loss = 0.69601 Val acc = 0.53202 \n",
      "2022-12-20 18:17:58.446417 Epoch 37 \tTrain Loss = 0.67750 Train acc = 0.57120  Val Loss = 0.69605 Val acc = 0.53154 \n",
      "2022-12-20 18:17:58.633916 Epoch 38 \tTrain Loss = 0.67695 Train acc = 0.57631  Val Loss = 0.69477 Val acc = 0.53869 \n",
      "2022-12-20 18:17:58.780577 Epoch 39 \tTrain Loss = 0.67640 Train acc = 0.57961  Val Loss = 0.69401 Val acc = 0.54503 \n",
      "2022-12-20 18:17:58.959046 Epoch 40 \tTrain Loss = 0.67610 Train acc = 0.57983  Val Loss = 0.69382 Val acc = 0.54846 \n",
      "2022-12-20 18:17:59.124422 Epoch 41 \tTrain Loss = 0.67545 Train acc = 0.58160  Val Loss = 0.69312 Val acc = 0.54886 \n",
      "2022-12-20 18:17:59.291973 Epoch 42 \tTrain Loss = 0.67491 Train acc = 0.58228  Val Loss = 0.69188 Val acc = 0.55520 \n",
      "2022-12-20 18:17:59.475483 Epoch 43 \tTrain Loss = 0.67453 Train acc = 0.58512  Val Loss = 0.69228 Val acc = 0.55391 \n",
      "2022-12-20 18:17:59.627884 Epoch 44 \tTrain Loss = 0.67398 Train acc = 0.58697  Val Loss = 0.69180 Val acc = 0.55708 \n",
      "2022-12-20 18:17:59.805899 Epoch 45 \tTrain Loss = 0.67346 Train acc = 0.58897  Val Loss = 0.69142 Val acc = 0.55741 \n",
      "2022-12-20 18:17:59.966470 Epoch 46 \tTrain Loss = 0.67328 Train acc = 0.59049  Val Loss = 0.69051 Val acc = 0.55985 \n",
      "2022-12-20 18:18:00.142997 Epoch 47 \tTrain Loss = 0.67269 Train acc = 0.59322  Val Loss = 0.69047 Val acc = 0.55741 \n",
      "2022-12-20 18:18:00.313541 Epoch 48 \tTrain Loss = 0.67211 Train acc = 0.59334  Val Loss = 0.68971 Val acc = 0.56025 \n",
      "2022-12-20 18:18:00.472117 Epoch 49 \tTrain Loss = 0.67188 Train acc = 0.59602  Val Loss = 0.68959 Val acc = 0.55896 \n",
      "2022-12-20 18:18:00.654629 Epoch 50 \tTrain Loss = 0.67114 Train acc = 0.59832  Val Loss = 0.68897 Val acc = 0.56139 \n",
      "2022-12-20 18:18:00.815662 Epoch 51 \tTrain Loss = 0.67111 Train acc = 0.59800  Val Loss = 0.68872 Val acc = 0.55270 \n",
      "2022-12-20 18:18:00.978115 Epoch 52 \tTrain Loss = 0.67023 Train acc = 0.60118  Val Loss = 0.68767 Val acc = 0.56025 \n",
      "2022-12-20 18:18:01.126323 Epoch 53 \tTrain Loss = 0.66997 Train acc = 0.60073  Val Loss = 0.68760 Val acc = 0.56213 \n",
      "2022-12-20 18:18:01.312897 Epoch 54 \tTrain Loss = 0.66963 Train acc = 0.60172  Val Loss = 0.68706 Val acc = 0.56806 \n",
      "2022-12-20 18:18:01.465310 Epoch 55 \tTrain Loss = 0.66917 Train acc = 0.60230  Val Loss = 0.68740 Val acc = 0.56523 \n",
      "2022-12-20 18:18:01.613912 Epoch 56 \tTrain Loss = 0.66868 Train acc = 0.60244  Val Loss = 0.68655 Val acc = 0.56604 \n",
      "2022-12-20 18:18:01.759524 Epoch 57 \tTrain Loss = 0.66846 Train acc = 0.60300  Val Loss = 0.68586 Val acc = 0.56294 \n",
      "2022-12-20 18:18:01.955532 Epoch 58 \tTrain Loss = 0.66795 Train acc = 0.60528  Val Loss = 0.68521 Val acc = 0.56766 \n",
      "2022-12-20 18:18:02.115107 Epoch 59 \tTrain Loss = 0.66762 Train acc = 0.60740  Val Loss = 0.68552 Val acc = 0.56759 \n",
      "2022-12-20 18:18:02.301606 Epoch 60 \tTrain Loss = 0.66717 Train acc = 0.60869  Val Loss = 0.68448 Val acc = 0.57083 \n",
      "2022-12-20 18:18:02.448215 Epoch 61 \tTrain Loss = 0.66667 Train acc = 0.61296  Val Loss = 0.68434 Val acc = 0.57002 \n",
      "2022-12-20 18:18:02.614584 Epoch 62 \tTrain Loss = 0.66619 Train acc = 0.61441  Val Loss = 0.68397 Val acc = 0.57197 \n",
      "2022-12-20 18:18:02.773764 Epoch 63 \tTrain Loss = 0.66609 Train acc = 0.61465  Val Loss = 0.68386 Val acc = 0.57116 \n",
      "2022-12-20 18:18:02.962298 Epoch 64 \tTrain Loss = 0.66541 Train acc = 0.61553  Val Loss = 0.68358 Val acc = 0.57109 \n",
      "2022-12-20 18:18:03.108600 Epoch 65 \tTrain Loss = 0.66509 Train acc = 0.61767  Val Loss = 0.68275 Val acc = 0.57702 \n",
      "2022-12-20 18:18:03.262896 Epoch 66 \tTrain Loss = 0.66473 Train acc = 0.61623  Val Loss = 0.68250 Val acc = 0.57661 \n",
      "2022-12-20 18:18:03.425461 Epoch 67 \tTrain Loss = 0.66415 Train acc = 0.61738  Val Loss = 0.68259 Val acc = 0.57735 \n",
      "2022-12-20 18:18:03.593012 Epoch 68 \tTrain Loss = 0.66377 Train acc = 0.61852  Val Loss = 0.68199 Val acc = 0.57580 \n",
      "2022-12-20 18:18:03.752628 Epoch 69 \tTrain Loss = 0.66352 Train acc = 0.61753  Val Loss = 0.68126 Val acc = 0.57507 \n",
      "2022-12-20 18:18:03.927291 Epoch 70 \tTrain Loss = 0.66327 Train acc = 0.61792  Val Loss = 0.68145 Val acc = 0.58052 \n",
      "2022-12-20 18:18:04.090854 Epoch 71 \tTrain Loss = 0.66279 Train acc = 0.61937  Val Loss = 0.68173 Val acc = 0.57809 \n",
      "2022-12-20 18:18:04.258406 Epoch 72 \tTrain Loss = 0.66237 Train acc = 0.62022  Val Loss = 0.68048 Val acc = 0.58247 \n",
      "2022-12-20 18:18:04.412547 Epoch 73 \tTrain Loss = 0.66198 Train acc = 0.61878  Val Loss = 0.68043 Val acc = 0.58597 \n",
      "2022-12-20 18:18:04.576318 Epoch 74 \tTrain Loss = 0.66178 Train acc = 0.61861  Val Loss = 0.67959 Val acc = 0.58645 \n",
      "2022-12-20 18:18:04.729950 Epoch 75 \tTrain Loss = 0.66131 Train acc = 0.61994  Val Loss = 0.67961 Val acc = 0.58126 \n",
      "2022-12-20 18:18:04.889481 Epoch 76 \tTrain Loss = 0.66098 Train acc = 0.61951  Val Loss = 0.67942 Val acc = 0.57938 \n",
      "2022-12-20 18:18:05.040927 Epoch 77 \tTrain Loss = 0.66064 Train acc = 0.61976  Val Loss = 0.67877 Val acc = 0.58093 \n",
      "2022-12-20 18:18:05.202532 Epoch 78 \tTrain Loss = 0.66031 Train acc = 0.62051  Val Loss = 0.67825 Val acc = 0.58409 \n",
      "2022-12-20 18:18:05.359077 Epoch 79 \tTrain Loss = 0.65998 Train acc = 0.62120  Val Loss = 0.67903 Val acc = 0.57849 \n",
      "2022-12-20 18:18:05.514694 Epoch 80 \tTrain Loss = 0.65989 Train acc = 0.62045  Val Loss = 0.67835 Val acc = 0.57857 \n",
      "2022-12-20 18:18:05.669247 Epoch 81 \tTrain Loss = 0.65946 Train acc = 0.62147  Val Loss = 0.67828 Val acc = 0.57735 \n",
      "2022-12-20 18:18:05.828820 Epoch 82 \tTrain Loss = 0.65912 Train acc = 0.62217  Val Loss = 0.67739 Val acc = 0.57783 \n",
      "2022-12-20 18:18:05.983407 Epoch 83 \tTrain Loss = 0.65871 Train acc = 0.62302  Val Loss = 0.67766 Val acc = 0.57344 \n",
      "2022-12-20 18:18:06.140986 Epoch 84 \tTrain Loss = 0.65814 Train acc = 0.62477  Val Loss = 0.67667 Val acc = 0.57742 \n",
      "2022-12-20 18:18:06.292580 Epoch 85 \tTrain Loss = 0.65802 Train acc = 0.62588  Val Loss = 0.67713 Val acc = 0.57271 \n",
      "2022-12-20 18:18:06.452846 Epoch 86 \tTrain Loss = 0.65786 Train acc = 0.62658  Val Loss = 0.67596 Val acc = 0.57433 \n",
      "2022-12-20 18:18:06.634907 Epoch 87 \tTrain Loss = 0.65729 Train acc = 0.62802  Val Loss = 0.67599 Val acc = 0.57628 \n",
      "2022-12-20 18:18:06.795478 Epoch 88 \tTrain Loss = 0.65685 Train acc = 0.62875  Val Loss = 0.67637 Val acc = 0.57459 \n",
      "2022-12-20 18:18:06.941915 Epoch 89 \tTrain Loss = 0.65668 Train acc = 0.62902  Val Loss = 0.67597 Val acc = 0.57695 \n",
      "2022-12-20 18:18:07.091482 Epoch 90 \tTrain Loss = 0.65622 Train acc = 0.63045  Val Loss = 0.67528 Val acc = 0.58019 \n",
      "2022-12-20 18:18:07.245070 Epoch 91 \tTrain Loss = 0.65614 Train acc = 0.62972  Val Loss = 0.67590 Val acc = 0.57695 \n",
      "2022-12-20 18:18:07.394729 Epoch 92 \tTrain Loss = 0.65573 Train acc = 0.62984  Val Loss = 0.67562 Val acc = 0.58011 \n",
      "2022-12-20 18:18:07.555463 Epoch 93 \tTrain Loss = 0.65559 Train acc = 0.63113  Val Loss = 0.67581 Val acc = 0.58085 \n",
      "2022-12-20 18:18:07.710630 Epoch 94 \tTrain Loss = 0.65498 Train acc = 0.63371  Val Loss = 0.67363 Val acc = 0.58922 \n",
      "2022-12-20 18:18:07.860058 Epoch 95 \tTrain Loss = 0.65466 Train acc = 0.63555  Val Loss = 0.67370 Val acc = 0.58800 \n",
      "2022-12-20 18:18:08.016124 Epoch 96 \tTrain Loss = 0.65466 Train acc = 0.63539  Val Loss = 0.67456 Val acc = 0.58752 \n",
      "2022-12-20 18:18:08.164693 Epoch 97 \tTrain Loss = 0.65428 Train acc = 0.63593  Val Loss = 0.67400 Val acc = 0.59224 \n",
      "2022-12-20 18:18:08.319625 Epoch 98 \tTrain Loss = 0.65378 Train acc = 0.63739  Val Loss = 0.67440 Val acc = 0.59176 \n",
      "2022-12-20 18:18:08.473215 Epoch 99 \tTrain Loss = 0.65370 Train acc = 0.63908  Val Loss = 0.67306 Val acc = 0.59264 \n",
      "2022-12-20 18:18:08.631790 Epoch 100 \tTrain Loss = 0.65302 Train acc = 0.63996  Val Loss = 0.67382 Val acc = 0.59257 \n",
      "2022-12-20 18:18:08.786376 Epoch 101 \tTrain Loss = 0.65268 Train acc = 0.64156  Val Loss = 0.67332 Val acc = 0.59419 \n",
      "2022-12-20 18:18:08.946980 Epoch 102 \tTrain Loss = 0.65232 Train acc = 0.64325  Val Loss = 0.67270 Val acc = 0.59500 \n",
      "2022-12-20 18:18:09.103528 Epoch 103 \tTrain Loss = 0.65196 Train acc = 0.64512  Val Loss = 0.67256 Val acc = 0.59581 \n",
      "2022-12-20 18:18:09.265756 Epoch 104 \tTrain Loss = 0.65220 Train acc = 0.64448  Val Loss = 0.67192 Val acc = 0.59703 \n",
      "2022-12-20 18:18:09.441942 Epoch 105 \tTrain Loss = 0.65144 Train acc = 0.64624  Val Loss = 0.67242 Val acc = 0.59379 \n",
      "2022-12-20 18:18:09.600430 Epoch 106 \tTrain Loss = 0.65162 Train acc = 0.64547  Val Loss = 0.67288 Val acc = 0.59021 \n",
      "2022-12-20 18:18:09.750989 Epoch 107 \tTrain Loss = 0.65099 Train acc = 0.64652  Val Loss = 0.67173 Val acc = 0.59541 \n",
      "2022-12-20 18:18:09.905576 Epoch 108 \tTrain Loss = 0.65082 Train acc = 0.64678  Val Loss = 0.67133 Val acc = 0.59696 \n",
      "2022-12-20 18:18:10.051187 Epoch 109 \tTrain Loss = 0.65081 Train acc = 0.64719  Val Loss = 0.67153 Val acc = 0.59655 \n",
      "2022-12-20 18:18:10.208765 Epoch 110 \tTrain Loss = 0.64998 Train acc = 0.64752  Val Loss = 0.67036 Val acc = 0.59703 \n",
      "2022-12-20 18:18:10.358366 Epoch 111 \tTrain Loss = 0.64991 Train acc = 0.64850  Val Loss = 0.67124 Val acc = 0.59338 \n",
      "2022-12-20 18:18:10.515943 Epoch 112 \tTrain Loss = 0.64969 Train acc = 0.64934  Val Loss = 0.67103 Val acc = 0.59500 \n",
      "2022-12-20 18:18:10.669533 Epoch 113 \tTrain Loss = 0.64942 Train acc = 0.64992  Val Loss = 0.67031 Val acc = 0.59467 \n",
      "2022-12-20 18:18:10.823157 Epoch 114 \tTrain Loss = 0.64915 Train acc = 0.65047  Val Loss = 0.67077 Val acc = 0.59183 \n",
      "2022-12-20 18:18:10.975036 Epoch 115 \tTrain Loss = 0.64901 Train acc = 0.65046  Val Loss = 0.67000 Val acc = 0.59224 \n",
      "2022-12-20 18:18:11.135626 Epoch 116 \tTrain Loss = 0.64839 Train acc = 0.65020  Val Loss = 0.67005 Val acc = 0.59264 \n",
      "2022-12-20 18:18:11.286614 Epoch 117 \tTrain Loss = 0.64812 Train acc = 0.65122  Val Loss = 0.67025 Val acc = 0.59224 \n",
      "2022-12-20 18:18:11.445190 Epoch 118 \tTrain Loss = 0.64780 Train acc = 0.65077  Val Loss = 0.67042 Val acc = 0.59419 \n",
      "2022-12-20 18:18:11.597782 Epoch 119 \tTrain Loss = 0.64764 Train acc = 0.65032  Val Loss = 0.67045 Val acc = 0.59298 \n",
      "2022-12-20 18:18:11.760347 Epoch 120 \tTrain Loss = 0.64743 Train acc = 0.65045  Val Loss = 0.66955 Val acc = 0.59736 \n",
      "2022-12-20 18:18:11.916929 Epoch 121 \tTrain Loss = 0.64701 Train acc = 0.65262  Val Loss = 0.66956 Val acc = 0.59338 \n",
      "2022-12-20 18:18:12.074507 Epoch 122 \tTrain Loss = 0.64667 Train acc = 0.65335  Val Loss = 0.66986 Val acc = 0.59217 \n",
      "2022-12-20 18:18:12.253271 Epoch 123 \tTrain Loss = 0.64659 Train acc = 0.65216  Val Loss = 0.66949 Val acc = 0.59298 \n",
      "2022-12-20 18:18:12.412844 Epoch 124 \tTrain Loss = 0.64620 Train acc = 0.65304  Val Loss = 0.66899 Val acc = 0.59500 \n",
      "2022-12-20 18:18:12.574412 Epoch 125 \tTrain Loss = 0.64604 Train acc = 0.65215  Val Loss = 0.66939 Val acc = 0.59460 \n",
      "2022-12-20 18:18:12.730993 Epoch 126 \tTrain Loss = 0.64600 Train acc = 0.65230  Val Loss = 0.66858 Val acc = 0.59622 \n",
      "2022-12-20 18:18:12.883586 Epoch 127 \tTrain Loss = 0.64550 Train acc = 0.65303  Val Loss = 0.66796 Val acc = 0.59622 \n",
      "2022-12-20 18:18:13.044155 Epoch 128 \tTrain Loss = 0.64522 Train acc = 0.65446  Val Loss = 0.66821 Val acc = 0.59500 \n",
      "2022-12-20 18:18:13.188769 Epoch 129 \tTrain Loss = 0.64487 Train acc = 0.65488  Val Loss = 0.66836 Val acc = 0.59338 \n",
      "2022-12-20 18:18:13.344353 Epoch 130 \tTrain Loss = 0.64481 Train acc = 0.65588  Val Loss = 0.66776 Val acc = 0.59500 \n",
      "2022-12-20 18:18:13.493952 Epoch 131 \tTrain Loss = 0.64441 Train acc = 0.65586  Val Loss = 0.66929 Val acc = 0.59135 \n",
      "2022-12-20 18:18:13.646544 Epoch 132 \tTrain Loss = 0.64416 Train acc = 0.65574  Val Loss = 0.66820 Val acc = 0.59298 \n",
      "2022-12-20 18:18:13.796713 Epoch 133 \tTrain Loss = 0.64431 Train acc = 0.65568  Val Loss = 0.66765 Val acc = 0.59581 \n",
      "2022-12-20 18:18:13.952297 Epoch 134 \tTrain Loss = 0.64362 Train acc = 0.65647  Val Loss = 0.66800 Val acc = 0.59257 \n",
      "2022-12-20 18:18:14.093287 Epoch 135 \tTrain Loss = 0.64349 Train acc = 0.65671  Val Loss = 0.66755 Val acc = 0.59452 \n",
      "2022-12-20 18:18:14.236937 Epoch 136 \tTrain Loss = 0.64315 Train acc = 0.65813  Val Loss = 0.66682 Val acc = 0.60053 \n",
      "2022-12-20 18:18:14.378523 Epoch 137 \tTrain Loss = 0.64291 Train acc = 0.65886  Val Loss = 0.66756 Val acc = 0.59931 \n",
      "2022-12-20 18:18:14.539095 Epoch 138 \tTrain Loss = 0.64264 Train acc = 0.65855  Val Loss = 0.66709 Val acc = 0.59696 \n",
      "2022-12-20 18:18:14.685703 Epoch 139 \tTrain Loss = 0.64243 Train acc = 0.65942  Val Loss = 0.66685 Val acc = 0.59581 \n",
      "2022-12-20 18:18:14.850262 Epoch 140 \tTrain Loss = 0.64198 Train acc = 0.66043  Val Loss = 0.66610 Val acc = 0.59744 \n",
      "2022-12-20 18:18:15.003852 Epoch 141 \tTrain Loss = 0.64171 Train acc = 0.66088  Val Loss = 0.66642 Val acc = 0.59622 \n",
      "2022-12-20 18:18:15.167414 Epoch 142 \tTrain Loss = 0.64201 Train acc = 0.65982  Val Loss = 0.66724 Val acc = 0.59379 \n",
      "2022-12-20 18:18:15.320331 Epoch 143 \tTrain Loss = 0.64122 Train acc = 0.66200  Val Loss = 0.66660 Val acc = 0.59419 \n",
      "2022-12-20 18:18:15.488893 Epoch 144 \tTrain Loss = 0.64100 Train acc = 0.66200  Val Loss = 0.66629 Val acc = 0.59581 \n",
      "2022-12-20 18:18:15.644159 Epoch 145 \tTrain Loss = 0.64119 Train acc = 0.66023  Val Loss = 0.66658 Val acc = 0.59419 \n",
      "2022-12-20 18:18:15.808719 Epoch 146 \tTrain Loss = 0.64064 Train acc = 0.66299  Val Loss = 0.66691 Val acc = 0.59298 \n",
      "2022-12-20 18:18:15.962309 Epoch 147 \tTrain Loss = 0.64049 Train acc = 0.66226  Val Loss = 0.66626 Val acc = 0.59500 \n",
      "2022-12-20 18:18:16.127871 Epoch 148 \tTrain Loss = 0.63996 Train acc = 0.66257  Val Loss = 0.66699 Val acc = 0.59371 \n",
      "2022-12-20 18:18:16.278463 Epoch 149 \tTrain Loss = 0.64008 Train acc = 0.66124  Val Loss = 0.66606 Val acc = 0.59736 \n",
      "2022-12-20 18:18:16.447012 Epoch 150 \tTrain Loss = 0.64009 Train acc = 0.66181  Val Loss = 0.66595 Val acc = 0.59736 \n",
      "2022-12-20 18:18:16.601598 Epoch 151 \tTrain Loss = 0.63946 Train acc = 0.66209  Val Loss = 0.66605 Val acc = 0.59850 \n",
      "2022-12-20 18:18:16.767977 Epoch 152 \tTrain Loss = 0.63900 Train acc = 0.66356  Val Loss = 0.66516 Val acc = 0.60517 \n",
      "2022-12-20 18:18:16.918554 Epoch 153 \tTrain Loss = 0.63915 Train acc = 0.66383  Val Loss = 0.66485 Val acc = 0.60680 \n",
      "2022-12-20 18:18:17.084322 Epoch 154 \tTrain Loss = 0.63892 Train acc = 0.66293  Val Loss = 0.66618 Val acc = 0.60396 \n",
      "2022-12-20 18:18:17.238348 Epoch 155 \tTrain Loss = 0.63851 Train acc = 0.66469  Val Loss = 0.66528 Val acc = 0.60639 \n",
      "2022-12-20 18:18:17.397921 Epoch 156 \tTrain Loss = 0.63818 Train acc = 0.66498  Val Loss = 0.66455 Val acc = 0.60444 \n",
      "2022-12-20 18:18:17.550513 Epoch 157 \tTrain Loss = 0.63762 Train acc = 0.66554  Val Loss = 0.66610 Val acc = 0.60160 \n",
      "2022-12-20 18:18:17.712196 Epoch 158 \tTrain Loss = 0.63792 Train acc = 0.66480  Val Loss = 0.66435 Val acc = 0.60565 \n",
      "2022-12-20 18:18:17.862795 Epoch 159 \tTrain Loss = 0.63750 Train acc = 0.66481  Val Loss = 0.66400 Val acc = 0.60565 \n",
      "2022-12-20 18:18:18.024362 Epoch 160 \tTrain Loss = 0.63715 Train acc = 0.66641  Val Loss = 0.66561 Val acc = 0.60160 \n",
      "2022-12-20 18:18:18.181940 Epoch 161 \tTrain Loss = 0.63726 Train acc = 0.66723  Val Loss = 0.66482 Val acc = 0.60322 \n",
      "2022-12-20 18:18:18.342510 Epoch 162 \tTrain Loss = 0.63685 Train acc = 0.66794  Val Loss = 0.66471 Val acc = 0.60363 \n",
      "2022-12-20 18:18:18.497321 Epoch 163 \tTrain Loss = 0.63653 Train acc = 0.66866  Val Loss = 0.66469 Val acc = 0.60322 \n",
      "2022-12-20 18:18:18.662837 Epoch 164 \tTrain Loss = 0.63605 Train acc = 0.66982  Val Loss = 0.66468 Val acc = 0.60200 \n",
      "2022-12-20 18:18:18.816010 Epoch 165 \tTrain Loss = 0.63638 Train acc = 0.66906  Val Loss = 0.66415 Val acc = 0.60606 \n",
      "2022-12-20 18:18:18.978577 Epoch 166 \tTrain Loss = 0.63632 Train acc = 0.66818  Val Loss = 0.66549 Val acc = 0.60119 \n",
      "2022-12-20 18:18:19.138149 Epoch 167 \tTrain Loss = 0.63566 Train acc = 0.66964  Val Loss = 0.66397 Val acc = 0.60241 \n",
      "2022-12-20 18:18:19.295729 Epoch 168 \tTrain Loss = 0.63549 Train acc = 0.67021  Val Loss = 0.66378 Val acc = 0.60525 \n",
      "2022-12-20 18:18:19.453306 Epoch 169 \tTrain Loss = 0.63538 Train acc = 0.66976  Val Loss = 0.66444 Val acc = 0.60477 \n",
      "2022-12-20 18:18:19.622854 Epoch 170 \tTrain Loss = 0.63532 Train acc = 0.67047  Val Loss = 0.66498 Val acc = 0.60355 \n",
      "2022-12-20 18:18:19.780432 Epoch 171 \tTrain Loss = 0.63480 Train acc = 0.67035  Val Loss = 0.66381 Val acc = 0.60558 \n",
      "2022-12-20 18:18:19.945278 Epoch 172 \tTrain Loss = 0.63456 Train acc = 0.67181  Val Loss = 0.66554 Val acc = 0.60469 \n",
      "2022-12-20 18:18:20.098867 Epoch 173 \tTrain Loss = 0.63411 Train acc = 0.67123  Val Loss = 0.66484 Val acc = 0.60436 \n",
      "2022-12-20 18:18:20.266352 Epoch 174 \tTrain Loss = 0.63411 Train acc = 0.67048  Val Loss = 0.66451 Val acc = 0.60396 \n",
      "2022-12-20 18:18:20.422392 Epoch 175 \tTrain Loss = 0.63370 Train acc = 0.67121  Val Loss = 0.66512 Val acc = 0.60315 \n",
      "2022-12-20 18:18:20.587057 Epoch 176 \tTrain Loss = 0.63341 Train acc = 0.67123  Val Loss = 0.66483 Val acc = 0.60355 \n",
      "2022-12-20 18:18:20.743639 Epoch 177 \tTrain Loss = 0.63340 Train acc = 0.67121  Val Loss = 0.66452 Val acc = 0.60355 \n",
      "2022-12-20 18:18:20.908003 Epoch 178 \tTrain Loss = 0.63345 Train acc = 0.67104  Val Loss = 0.66397 Val acc = 0.60436 \n",
      "Early stopping at epoch: 178\n",
      "Best at epoch 168:\n",
      "Train Loss = 0.63549 Train acc = 0.67021 \n",
      "Val Loss = 0.66378 Val acc = 0.60525 \n",
      "Test Loss = 0.67205 Test acc = 0.61694 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def onehot_decode(label):\n",
    "    return torch.argmax(label, dim=1)\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    pred_decode = onehot_decode(predictions)\n",
    "    true_decode = targets\n",
    "\n",
    "    assert len(pred_decode) == len(true_decode)\n",
    "\n",
    "    acc = torch.mean((pred_decode == true_decode).float())\n",
    "\n",
    "    return float(acc)\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users,\n",
    "        embedding_dim=16,\n",
    "        hidden_dim=32,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.input_dim = embedding_dim * 2 + 1\n",
    "\n",
    "        self.user_embedding_layer = nn.Embedding(\n",
    "            num_embeddings=num_users, embedding_dim=embedding_dim, padding_idx=-1\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Linear(self.input_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 2, 3(from, to, label))\n",
    "\n",
    "        last_tx = x[:, 0, :]\n",
    "        cur_tx = x[:, 1, :]\n",
    "\n",
    "        last_from_user = last_tx[:, 0].long()\n",
    "        # last_to_user = last_tx[:, 1].long()\n",
    "        last_label = last_tx[:, 2][:, None]\n",
    "\n",
    "        cur_from_user = cur_tx[:, 0].long()\n",
    "        # cur_to_user = cur_tx[:, 1].long()\n",
    "\n",
    "        last_from_embedding = self.user_embedding_layer(\n",
    "            last_from_user\n",
    "        )  # (batch_size, embedding_dim)\n",
    "        # last_to_embedding = self.user_embedding_layer(last_to_user)\n",
    "\n",
    "        cur_from_embedding = self.user_embedding_layer(cur_from_user)\n",
    "        # cur_to_embedding = self.user_embedding_layer(cur_to_user)\n",
    "\n",
    "        input = torch.concat(\n",
    "            (\n",
    "                last_from_embedding,\n",
    "                # last_to_embedding,\n",
    "                cur_from_embedding,\n",
    "                # cur_to_embedding,\n",
    "                last_label,\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        out = self.mlp(input)\n",
    "        out = torch.softmax(out, dim=1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        return self.user_embedding_layer.weight.cpu().detach().numpy()\n",
    "\n",
    "def gen_xy(sequence):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    ---\n",
    "    x: (num_samples, 2, num_features)\n",
    "    y: (num_samples,) 1-d vec for labels\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = [], []\n",
    "    for i in range(len(sequence) - 2):\n",
    "        x.append(sequence[i : i + 2])\n",
    "        y.append(sequence[i + 2 - 1])\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if len(y.shape) > 1:\n",
    "        y = y[:, -1]\n",
    "\n",
    "    return torch.FloatTensor(x), torch.LongTensor(y)\n",
    "\n",
    "\n",
    "def get_dataloaders(sequence, train_size=0.7, val_size=0.1, batch_size=64):\n",
    "    x, y = gen_xy(sequence)\n",
    "\n",
    "    split1 = int(len(x) * train_size)\n",
    "    split2 = int(len(sequence) * (train_size + val_size))\n",
    "\n",
    "    x_train, y_train = x[:split1], y[:split1]\n",
    "    x_val, y_val = x[split1:split2], y[split1:split2]\n",
    "    x_test, y_test = x[split2:], y[split2:]\n",
    "\n",
    "    print(f\"Trainset:\\tx-{x_train.size()}\\ty-{y_train.size()}\")\n",
    "    print(f\"Valset:  \\tx-{x_val.size()}  \\ty-{y_val.size()}\")\n",
    "    print(f\"Testset:\\tx-{x_test.size()}\\ty-{y_test.size()}\")\n",
    "\n",
    "    trainset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    valset = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "    testset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "    trainset_loader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    valset_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    testset_loader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return trainset_loader, valset_loader, testset_loader\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, valset_loader, criterion):\n",
    "    model.eval()\n",
    "    batch_loss_list = []\n",
    "    batch_acc_list = []\n",
    "    for x_batch, y_batch in valset_loader:\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "        out_batch = model.forward(x_batch)\n",
    "        loss = criterion.forward(out_batch, y_batch)\n",
    "        batch_loss_list.append(loss.item())\n",
    "\n",
    "        acc = accuracy(out_batch, y_batch)\n",
    "        batch_acc_list.append(acc)\n",
    "\n",
    "    return np.mean(batch_loss_list), np.mean(batch_acc_list)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, trainset_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    batch_loss_list = []\n",
    "    batch_acc_list = []\n",
    "    for x_batch, y_batch in trainset_loader:\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "        out_batch = model.forward(x_batch)\n",
    "        loss = criterion.forward(out_batch, y_batch)\n",
    "        batch_loss_list.append(loss.item())\n",
    "\n",
    "        acc = accuracy(out_batch, y_batch)\n",
    "        batch_acc_list.append(acc)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return np.mean(batch_loss_list), np.mean(batch_acc_list)\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    trainset_loader,\n",
    "    valset_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    max_epochs=100,\n",
    "    early_stop=10,\n",
    "    verbose=1,\n",
    "    plot=False,\n",
    "):\n",
    "    wait = 0\n",
    "    min_val_loss = np.inf\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, trainset_loader, optimizer, criterion\n",
    "        )\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "\n",
    "        val_loss, val_acc = eval_model(model, valset_loader, criterion)\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "\n",
    "        if (epoch + 1) % verbose == 0:\n",
    "            print(\n",
    "                datetime.datetime.now(),\n",
    "                \"Epoch\",\n",
    "                epoch + 1,\n",
    "                \"\\tTrain Loss = %.5f\" % train_loss,\n",
    "                \"Train acc = %.5f \" % train_acc,\n",
    "                \"Val Loss = %.5f\" % val_loss,\n",
    "                \"Val acc = %.5f \" % val_acc,\n",
    "            )\n",
    "\n",
    "        if val_loss < min_val_loss:\n",
    "            wait = 0\n",
    "            min_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            best_state_dict = model.state_dict()\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= early_stop:\n",
    "                print(f\"Early stopping at epoch: {epoch+1}\")\n",
    "                print(f\"Best at epoch {best_epoch+1}:\")\n",
    "                print(\n",
    "                    \"Train Loss = %.5f\" % train_loss_list[best_epoch],\n",
    "                    \"Train acc = %.5f \" % train_acc_list[best_epoch],\n",
    "                )\n",
    "                print(\n",
    "                    \"Val Loss = %.5f\" % val_loss_list[best_epoch],\n",
    "                    \"Val acc = %.5f \" % val_acc_list[best_epoch],\n",
    "                )\n",
    "\n",
    "                break\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(range(0, epoch + 1), train_loss_list, \"-\", label=\"Train Loss\")\n",
    "        plt.plot(range(0, epoch + 1), val_loss_list, \"-\", label=\"Val Loss\")\n",
    "        plt.title(\"Epoch-Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(range(0, epoch + 1), train_acc_list, \"-\", label=\"Train Acc\")\n",
    "        plt.plot(range(0, epoch + 1), val_acc_list, \"-\", label=\"Val Acc\")\n",
    "        plt.title(\"Epoch-Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_users = 500\n",
    "    embedding_dim = 8\n",
    "    hidden_dim = 16\n",
    "    batch_size = 64\n",
    "    lr = 1e-4\n",
    "\n",
    "    max_epochs = 1000\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        GPU_ID = 0\n",
    "        DEVICE = torch.device(f\"cuda:{GPU_ID}\")\n",
    "    else:\n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "        \n",
    "    sequence = pd.read_pickle(data_path)[\n",
    "        [\"from_user_id\", \"to_user_id\", \"label\"]\n",
    "    ].values\n",
    "\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(\n",
    "        sequence, batch_size=batch_size, train_size=0.7, val_size=0.1\n",
    "    )\n",
    "\n",
    "    model = BinaryClassifier(\n",
    "        num_users=num_users, embedding_dim=embedding_dim, hidden_dim=hidden_dim\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model = train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        max_epochs=max_epochs,\n",
    "        early_stop=10,\n",
    "        verbose=1,\n",
    "        plot=False,\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = eval_model(model, test_loader, criterion)\n",
    "    print(\"Test Loss = %.5f\" % test_loss, \"Test acc = %.5f \" % test_acc)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6418133bade46933378562b9c4edca5abd2ee756fb90d7ff79aecdfe8ac5a3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
